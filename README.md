# 🖐️ Hand Gesture-Based Virtual Application

A real-time hand gesture recognition system built using **MediaPipe** and **OpenCV**, enabling natural, touchless interaction with digital interfaces. This project includes a virtual keyboard for text-to-speech conversion, a virtual mouse for image control, click operations, and gesture-based audio/video playback control—all without using any machine learning models.

---

## ✨ Features

- 🔤 **Virtual Keyboard**: Convert text to speech using hand gestures.
- 🖱️ **Virtual Mouse**: Gesture-based click, movement, and control.
- 🔍 **Zoom In/Out**: Control image zoom using pinch gestures.
- 🔊 **Audio/Video Control**: Play, pause, volume control via hand gestures.
- 🎯 **Real-Time Performance**: Accurate landmark detection and response.
- 🧠 **No ML Model Required**: Purely based on MediaPipe and OpenCV.

---

## 🛠️ Tech Stack

- **Python 3.x**
- **MediaPipe**
- **OpenCV**
- **pyttsx3** – Text-to-speech engine
- **Tkinter / OpenCV GUI** – For interface (optional)

---

## 🚀 Getting Started

### Prerequisites

Make sure you have Python and `pip` installed.

### Installation

```bash
git clone https://github.com/yourusername/hand-gesture-virtual-app.git
cd hand-gesture-virtual-app
pip install -r requirements.txt
