# ğŸ–ï¸ Hand Gesture-Based Virtual Application

A real-time hand gesture recognition system built using **MediaPipe** and **OpenCV**, enabling natural, touchless interaction with digital interfaces. This project includes a virtual keyboard for text-to-speech conversion, a virtual mouse for image control, click operations, and gesture-based audio/video playback controlâ€”all without using any machine learning models.

---

## âœ¨ Features

- ğŸ”¤ **Virtual Keyboard**: Convert text to speech using hand gestures.
- ğŸ–±ï¸ **Virtual Mouse**: Gesture-based click, movement, and control.
- ğŸ” **Zoom In/Out**: Control image zoom using pinch gestures.
- ğŸ”Š **Audio/Video Control**: Play, pause, volume control via hand gestures.
- ğŸ¯ **Real-Time Performance**: Accurate landmark detection and response.
- ğŸ§  **No ML Model Required**: Purely based on MediaPipe and OpenCV.

---

## ğŸ› ï¸ Tech Stack

- **Python 3.x**
- **MediaPipe**
- **OpenCV**
- **pyttsx3** â€“ Text-to-speech engine
- **Tkinter / OpenCV GUI** â€“ For interface (optional)

---

## ğŸš€ Getting Started

### Prerequisites

Make sure you have Python and `pip` installed.

### Installation

```bash
git clone https://github.com/yourusername/hand-gesture-virtual-app.git
cd hand-gesture-virtual-app
pip install -r requirements.txt
